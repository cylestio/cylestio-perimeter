# Agent Inspector - Cursor Integration

## Terminology

- **Agent**: A project/codebase being analyzed (what you're developing)
- **System Prompt**: An individual LLM agent instance identified by its system prompt hash

## MCP Server Connection
Agent Inspector MCP endpoint at `http://localhost:7100/mcp` provides security analysis tools.
- **Proxy:** `http://localhost:4000` (point your agent here)
- **Dashboard/MCP:** `http://localhost:7100`

## Available MCP Tools (13 total)

### Analysis Tools
- `get_security_patterns` - Retrieve OWASP LLM Top 10 patterns
- `create_analysis_session` - Start session for an agent (agent_id required)
- `store_finding` - Record a security finding
- `complete_analysis_session` - Finalize session and calculate risk score
- `get_findings` - Retrieve stored findings
- `update_finding_status` - Mark finding as FIXED or IGNORED

### Knowledge Tools
- `get_owasp_control` - Get specific OWASP control details (LLM01-LLM10)
- `get_fix_template` - Get remediation template for a finding type

### Agent Lifecycle Tools
- `get_agent_state` - Check what analysis exists (static/dynamic/both)
- `get_tool_usage_summary` - Get tool usage patterns from dynamic sessions
- `get_agent_correlation` - Correlate static findings with dynamic runtime

### System Prompt Discovery Tools
- `get_system_prompts` - List system prompts (filter by agent_id or "unlinked")
- `update_system_prompt_info` - Link system prompts to agents, set display names

## AUTOMATIC WORKFLOW

When user asks for security analysis, follow this flow:

### Step 1: Derive agent_id (DON'T ASK USER)
Auto-derive from (priority order):
1. Git remote: `github.com/acme/my-agent.git` → `my-agent`
2. Package name: `pyproject.toml` or `package.json`
3. Folder name: `/projects/my-bot` → `my-bot`

### Step 2: Check Current State
```
get_agent_state(agent_id)
```
- `NO_DATA` → Run static analysis
- `STATIC_ONLY` → Inform user to run dynamic tests
- `DYNAMIC_ONLY` → Run static analysis, then correlate
- `COMPLETE` → Run correlation, report unified results

### Step 3: Discover & Link System Prompts (if dynamic data exists)
```
get_system_prompts("unlinked")
```
Link unlinked system prompts:
```
update_system_prompt_info(system_prompt_id, agent_id="the-agent-id")
```

### Step 4: Run Static Analysis
1. `get_security_patterns()` - NEVER hardcode patterns
2. `create_analysis_session(agent_id, "STATIC")`
3. Analyze code and `store_finding(...)` for each issue
4. `complete_analysis_session(session_id)`

### Step 5: Correlate (when both static + dynamic exist)
```
get_agent_correlation(agent_id)
get_tool_usage_summary(agent_id)
```
Report:
- **VALIDATED**: Finding's tool was called at runtime
- **UNEXERCISED**: Tool never called in tests

### Step 6: Name System Prompts (optional)
```
update_system_prompt_info(system_prompt_id, display_name="Customer Support Bot", description="...")
```

### Step 7: Report Results
Include dashboard URL: `http://localhost:7100/agent/{agent_id}`

## Dynamic Analysis Setup

Tell user to configure their agent's base_url:
```python
# OpenAI
client = OpenAI(base_url=f"http://localhost:4000/agent/{AGENT_ID}")

# Anthropic  
client = Anthropic(base_url=f"http://localhost:4000/agent/{AGENT_ID}")
```

## Fix Workflow
1. `get_findings(agent_id, status="OPEN")`
2. `get_fix_template(finding_type)`
3. Apply fix per guidance
4. `update_finding_status(finding_id, "FIXED", notes="...")`

## Key Rules
1. **Auto-derive** agent_id - don't ask user
2. **Auto-link** unlinked system prompts via `update_system_prompt_info`
3. **Auto-correlate** when both static + dynamic data exist
4. **Never hardcode** security patterns - always fetch from MCP
5. **Same agent_id** for static and dynamic = unified results
